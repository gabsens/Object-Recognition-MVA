{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning: Densenet-161\n",
    "\n",
    "## The code that produces the .csv file is at the very bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.autograd import Variable\n",
    "import PIL.Image as Image\n",
    "from torchvision import models\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    )\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "        ])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "        root='./bird_dataset/train_images/', \n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "valid_dataset = ImageFolder(\n",
    "        root='./bird_dataset/val_images/', \n",
    "        transform=valid_transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 1  #1 if cuda\n",
    "pin_memory = True  #true if cuda\n",
    "shuffle = True\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "cuda_avail = torch.cuda.is_available()\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 20)      \n",
    "\n",
    "if cuda_avail:                                 \n",
    "    model_ft = model_ft.cuda()   \n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()          \n",
    "optimizer = SGD(model_ft.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#inspired from\n",
    "# https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "\n",
    "\n",
    "def save_models(epoch):\n",
    "    torch.save(model_ft.state_dict(), \"densenetmodel_{}.model\".format(epoch))\n",
    "    print(\"Checkpoint saved\")\n",
    "\n",
    "def test():\n",
    "    model_ft.eval()\n",
    "    test_acc = 0.0\n",
    "    for data in valid_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_ft(images)\n",
    "        _,prediction = torch.max(outputs.data, 1)\n",
    "        test_acc += (prediction == labels).sum().item()\n",
    "        \n",
    "\n",
    "\n",
    "  \n",
    "    test_acc = test_acc / 103\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "best_acc_train = 0.0\n",
    "best_acc_test = 0.0\n",
    "\n",
    "def train(num_epochs):\n",
    "    global best_acc_train\n",
    "    global best_acc_test\n",
    "    for epoch in range(num_epochs):\n",
    "        model_ft.train()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_ft(images)\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.cpu().item() * images.size(0)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            \n",
    "            train_acc += (prediction == labels).sum().item()\n",
    "\n",
    "\n",
    "        train_acc = train_acc / 1082\n",
    "        train_loss = train_loss / 1082\n",
    "\n",
    "        test_acc = test()\n",
    "\n",
    "        if (test_acc >= best_acc_test) and (train_acc >= best_acc_train):\n",
    "            save_models(epoch)\n",
    "            best_acc_test = test_acc\n",
    "            best_acc_train = train_acc\n",
    "\n",
    "\n",
    "        # Print the metrics\n",
    "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}\".format(epoch, train_acc, train_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved\n",
      "Epoch 0, Train Accuracy: 0.28650646950092423 , TrainLoss: 3.9834477813318787 , Test Accuracy: 0.7475728155339806\n",
      "Checkpoint saved\n",
      "Epoch 1, Train Accuracy: 0.6719038817005545 , TrainLoss: 1.0638933970615296 , Test Accuracy: 0.8155339805825242\n",
      "Checkpoint saved\n",
      "Epoch 2, Train Accuracy: 0.7818853974121996 , TrainLoss: 0.7735497939388325 , Test Accuracy: 0.8446601941747572\n",
      "Checkpoint saved\n",
      "Epoch 3, Train Accuracy: 0.7846580406654344 , TrainLoss: 0.6915447671179851 , Test Accuracy: 0.8737864077669902\n",
      "Epoch 4, Train Accuracy: 0.8031423290203327 , TrainLoss: 0.6565020024886634 , Test Accuracy: 0.8252427184466019\n",
      "Epoch 5, Train Accuracy: 0.821626617375231 , TrainLoss: 0.583801226342672 , Test Accuracy: 0.8543689320388349\n",
      "Epoch 6, Train Accuracy: 0.8345656192236599 , TrainLoss: 0.5492665238829946 , Test Accuracy: 0.8446601941747572\n",
      "Epoch 7, Train Accuracy: 0.8512014787430684 , TrainLoss: 0.5411371585401722 , Test Accuracy: 0.8640776699029126\n",
      "Epoch 8, Train Accuracy: 0.8456561922365989 , TrainLoss: 0.4989077978648672 , Test Accuracy: 0.8640776699029126\n",
      "Checkpoint saved\n",
      "Epoch 9, Train Accuracy: 0.8761552680221811 , TrainLoss: 0.42457263901581827 , Test Accuracy: 0.883495145631068\n",
      "Epoch 10, Train Accuracy: 0.8761552680221811 , TrainLoss: 0.4207073153717901 , Test Accuracy: 0.8543689320388349\n",
      "Epoch 11, Train Accuracy: 0.8770794824399261 , TrainLoss: 0.4156640794493134 , Test Accuracy: 0.8640776699029126\n",
      "Epoch 12, Train Accuracy: 0.8826247689463955 , TrainLoss: 0.4180325510155912 , Test Accuracy: 0.8737864077669902\n",
      "Epoch 13, Train Accuracy: 0.88909426987061 , TrainLoss: 0.383988975817527 , Test Accuracy: 0.883495145631068\n",
      "Epoch 14, Train Accuracy: 0.8872458410351202 , TrainLoss: 0.3849930285085371 , Test Accuracy: 0.8543689320388349\n",
      "Epoch 15, Train Accuracy: 0.8955637707948244 , TrainLoss: 0.3467266088052069 , Test Accuracy: 0.8640776699029126\n",
      "Checkpoint saved\n",
      "Epoch 16, Train Accuracy: 0.9085027726432532 , TrainLoss: 0.30838277032547207 , Test Accuracy: 0.9029126213592233\n",
      "Epoch 17, Train Accuracy: 0.9094269870609981 , TrainLoss: 0.31440164201140625 , Test Accuracy: 0.8737864077669902\n",
      "Epoch 18, Train Accuracy: 0.8872458410351202 , TrainLoss: 0.3576062863172753 , Test Accuracy: 0.8640776699029126\n",
      "Epoch 19, Train Accuracy: 0.9177449168207024 , TrainLoss: 0.29041027014665377 , Test Accuracy: 0.8932038834951457\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Accuracy: 0.9085027726432532 , TrainLoss: 0.2950058912173217 , Test Accuracy: 0.883495145631068\n",
      "Epoch 1, Train Accuracy: 0.9094269870609981 , TrainLoss: 0.3191073614821637 , Test Accuracy: 0.9029126213592233\n",
      "Epoch 2, Train Accuracy: 0.9038817005545287 , TrainLoss: 0.3278001830009348 , Test Accuracy: 0.9223300970873787\n",
      "Epoch 3, Train Accuracy: 0.9177449168207024 , TrainLoss: 0.2944378697497567 , Test Accuracy: 0.8737864077669902\n",
      "Epoch 4, Train Accuracy: 0.9075785582255084 , TrainLoss: 0.2885306401388262 , Test Accuracy: 0.8932038834951457\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load('./resnetmodel_16.model'))\n",
    "optimizer = SGD(model_ft.parameters(), lr=0.00001, momentum=0.1)\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(torch.load('./resnetmodel_16.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './bird_dataset/test_images/mistery_category'\n",
    "output_file = open(\"testdensenet.csv\", \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "for f in os.listdir(test_dir):\n",
    "    if 'jpg' in f:\n",
    "        data = valid_transform(pil_loader(test_dir + '/' + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        if cuda_avail:\n",
    "            data = data.cuda()\n",
    "        model_ft.eval()\n",
    "        output = model_ft(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
